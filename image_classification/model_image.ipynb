{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import cPickle as pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the real project class, we use argparse (https://docs.python.org/3/library/argparse.html)\n",
    "class FakeArgParse():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = FakeArgParse()\n",
    "\n",
    "#general model params\n",
    "args.train = False\n",
    "args.rnn_size = 100 #400 hidden units\n",
    "args.tsteps = 256 if args.train else 1\n",
    "args.batch_size = 32 if args.train else 1\n",
    "args.nmixtures = 8 # number of Gaussian mixtures in MDN\n",
    "\n",
    "#window params\n",
    "args.kmixtures = 1 # number of Gaussian mixtures in attention mechanism (for soft convolution window)\n",
    "args.alphabet = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' #later we'll add an <UNK> slot for unknown chars\n",
    "args.tsteps_per_ascii = 25 # an approximate estimate\n",
    "\n",
    "#book-keeping\n",
    "args.save_path = './saved/model.ckpt'\n",
    "args.data_dir = './data'\n",
    "args.log_dir = './logs/'\n",
    "args.text = 'call me ishmael some years ago'\n",
    "args.style = -1 # don't use a custom style\n",
    "args.bias = 1.0\n",
    "args.eos_prob = 0.4 # threshold probability for ending a stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in real life the model is a class. I used this hack to make the iPython notebook more readable\n",
    "class FakeModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "model = FakeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.char_vec_len = len(args.alphabet) + 1 #plus one for <UNK> token\n",
    "model.ascii_steps = len(args.text)\n",
    "\n",
    "model.graves_initializer = tf.truncated_normal_initializer(mean=0., stddev=.075, seed=None, dtype=tf.float32)\n",
    "model.window_b_initializer = tf.truncated_normal_initializer(mean=-3.0, stddev=.25, seed=None, dtype=tf.float32)\n",
    "\n",
    "# ----- build the basic recurrent network architecture\n",
    "cell_func = tf.contrib.rnn.LSTMCell # could be GRUCell or RNNCell\n",
    "model.cell0 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
    "model.cell1 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
    "model.cell2 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
    "\n",
    "model.input_data = tf.placeholder(dtype=tf.float32, shape=[None, args.tsteps, 3])\n",
    "model.target_data = tf.placeholder(dtype=tf.float32, shape=[None, args.tsteps, 3])\n",
    "model.istate_cell0 = model.cell0.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
    "model.istate_cell1 = model.cell1.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
    "model.istate_cell2 = model.cell2.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
    "\n",
    "#slice the input volume into separate vols for each tstep\n",
    "inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(model.input_data, args.tsteps, 1)]\n",
    "\n",
    "#build model.cell0 computational graph\n",
    "outs_cell0, model.fstate_cell0 = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, model.istate_cell0, \\\n",
    "                                                       model.cell0, loop_function=None, scope='cell0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- build the gaussian character window\n",
    "def get_window(alpha, beta, kappa, c):\n",
    "    # phi -> [? x 1 x ascii_steps] and is a tf matrix\n",
    "    # c -> [? x ascii_steps x alphabet] and is a tf matrix\n",
    "    ascii_steps = c.get_shape()[1].value #number of items in sequence\n",
    "    phi = get_phi(ascii_steps, alpha, beta, kappa)\n",
    "    window = tf.matmul(phi,c)\n",
    "    window = tf.squeeze(window, [1]) # window ~ [?,alphabet]\n",
    "    return window, phi\n",
    "\n",
    "#get phi for all t,u (returns a [1 x tsteps] matrix) that defines the window\n",
    "def get_phi(ascii_steps, alpha, beta, kappa):\n",
    "    # alpha, beta, kappa -> [?,kmixtures,1] and each is a tf variable\n",
    "    u = np.linspace(0,ascii_steps-1,ascii_steps) # weight all the U items in the sequence\n",
    "    kappa_term = tf.square( tf.subtract(kappa,u))\n",
    "    exp_term = tf.multiply(-beta,kappa_term)\n",
    "    phi_k = tf.multiply(alpha, tf.exp(exp_term))\n",
    "    phi = tf.reduce_sum(phi_k,1, keep_dims=True)\n",
    "    return phi # phi ~ [?,1,ascii_steps]\n",
    "\n",
    "def get_window_params(i, out_cell0, kmixtures, prev_kappa, reuse=True):\n",
    "    hidden = out_cell0.get_shape()[1]\n",
    "    n_out = 3*kmixtures\n",
    "    with tf.variable_scope('window',reuse=reuse):\n",
    "        window_w = tf.get_variable(\"window_w\", [hidden, n_out], initializer=model.graves_initializer)\n",
    "        window_b = tf.get_variable(\"window_b\", [n_out], initializer=model.window_b_initializer)\n",
    "    abk_hats = tf.nn.xw_plus_b(out_cell0, window_w, window_b) # abk_hats ~ [?,n_out] = \"alpha, beta, kappa hats\"\n",
    "    abk = tf.exp(tf.reshape(abk_hats, [-1, 3*kmixtures,1]))\n",
    "\n",
    "    alpha, beta, kappa = tf.split(abk, 3, 1) # alpha_hat, etc ~ [?,kmixtures]\n",
    "    kappa = kappa + prev_kappa\n",
    "    return alpha, beta, kappa # each ~ [?,kmixtures,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_kappa = tf.placeholder(dtype=tf.float32, shape=[None, args.kmixtures, 1]) \n",
    "model.char_seq = tf.placeholder(dtype=tf.float32, shape=[None, model.ascii_steps, model.char_vec_len])\n",
    "wavg_prev_kappa = model.init_kappa\n",
    "prev_window = model.char_seq[:,0,:]\n",
    "\n",
    "#add gaussian window result\n",
    "reuse = False\n",
    "for i in range(len(outs_cell0)):\n",
    "    [alpha, beta, new_kappa] = get_window_params(i, outs_cell0[i], args.kmixtures, wavg_prev_kappa, reuse=reuse)\n",
    "    window, phi = get_window(alpha, beta, new_kappa, model.char_seq)\n",
    "    outs_cell0[i] = tf.concat((outs_cell0[i],window), 1) #concat outputs\n",
    "    outs_cell0[i] = tf.concat((outs_cell0[i],inputs[i]), 1) #concat input data\n",
    "#         prev_kappa = new_kappa #tf.ones_like(new_kappa, dtype=tf.float32, name=\"prev_kappa_ones\") #\n",
    "    wavg_prev_kappa = tf.reduce_mean( new_kappa, reduction_indices=1, keep_dims=True) # mean along kmixtures dimension\n",
    "    reuse = True\n",
    "model.window = window #save the last window (for generation)\n",
    "model.phi = phi #save the last window (for generation)\n",
    "model.new_kappa = new_kappa #save the last window (for generation)\n",
    "model.alpha = alpha #save the last window (for generation)\n",
    "model.wavg_prev_kappa = wavg_prev_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- finish building second recurrent cell\n",
    "outs_cell1, model.fstate_cell1 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell0, model.istate_cell1, model.cell1, \\\n",
    "                                                    loop_function=None, scope='cell1') #use scope from training\n",
    "\n",
    "# ----- finish building third recurrent cell\n",
    "outs_cell2, model.fstate_cell2 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell1, model.istate_cell2, model.cell2, \\\n",
    "                                                    loop_function=None, scope='cell2')\n",
    "\n",
    "out_cell2 = tf.reshape(tf.concat(outs_cell2, 1), [-1, args.rnn_size]) #concat outputs for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put a dense cap on top of the rnn cells (to interface with the mixture density network)\n",
    "n_out = 1 + args.nmixtures * 6 # params = end_of_stroke + 6 parameters per Gaussian\n",
    "with tf.variable_scope('mdn_dense'):\n",
    "    output_w = tf.get_variable(\"output_w\", [args.rnn_size, n_out], initializer=model.graves_initializer)\n",
    "    output_b = tf.get_variable(\"output_b\", [n_out], initializer=model.graves_initializer)\n",
    "\n",
    "output = tf.nn.xw_plus_b(out_cell2, output_w, output_b) #data flows through dense nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
