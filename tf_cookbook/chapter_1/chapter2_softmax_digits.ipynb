{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[[  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.  13.  15.  10.  15.\n",
      "    5.   0.   0.   3.  15.   2.   0.  11.   8.   0.   0.   4.  12.   0.\n",
      "    0.   8.   8.   0.   0.   5.   8.   0.   0.   9.   8.   0.   0.   4.\n",
      "   11.   0.   1.  12.   7.   0.   0.   2.  14.   5.  10.  12.   0.   0.\n",
      "    0.   0.   6.  13.  10.   0.   0.   0.]\n",
      " [  0.   0.   0.  12.  13.   5.   0.   0.   0.   0.   0.  11.  16.   9.\n",
      "    0.   0.   0.   0.   3.  15.  16.   6.   0.   0.   0.   7.  15.  16.\n",
      "   16.   2.   0.   0.   0.   0.   1.  16.  16.   3.   0.   0.   0.   0.\n",
      "    1.  16.  16.   6.   0.   0.   0.   0.   1.  16.  16.   6.   0.   0.\n",
      "    0.   0.   0.  11.  16.  10.   0.   0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJAMwQ0AyRDcAJDMfwFhTX+bEqVjSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3fc16d400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "\n",
    "digits = load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "\n",
    "label=digits.target\n",
    "\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "print(data.shape)\n",
    "print(data[:2])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(data, label,test_size=0.3, random_state=41)\n",
    "\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(x_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(x_train), batch_size)\n",
    "    x_batch = x_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-0958a6a4b8f4>:17: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 64]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.int64, [None]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([64, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "\n",
    "y_pred = tf.argmax(tf.nn.softmax(logits), dimension=1)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred, y)\n",
    "  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 training accuracy= 0.89101\n",
      "Epoch: 2 training accuracy= 0.921241\n",
      "Epoch: 3 training accuracy= 0.937152\n",
      "Epoch: 4 training accuracy= 0.937152\n",
      "Epoch: 5 training accuracy= 0.947494\n",
      "Epoch: 6 training accuracy= 0.959427\n",
      "Epoch: 7 training accuracy= 0.968178\n",
      "Epoch: 8 training accuracy= 0.959427\n",
      "Epoch: 9 training accuracy= 0.968178\n",
      "Epoch: 10 training accuracy= 0.97136\n",
      "Epoch: 11 training accuracy= 0.97136\n",
      "Epoch: 12 training accuracy= 0.972156\n",
      "Epoch: 13 training accuracy= 0.977725\n",
      "Epoch: 14 training accuracy= 0.974543\n",
      "Epoch: 15 training accuracy= 0.975338\n",
      "Epoch: 16 training accuracy= 0.976929\n",
      "Epoch: 17 training accuracy= 0.97852\n",
      "Epoch: 18 training accuracy= 0.977725\n",
      "Epoch: 19 training accuracy= 0.977725\n",
      "Epoch: 20 training accuracy= 0.97852\n",
      "Epoch: 21 training accuracy= 0.977725\n",
      "Epoch: 22 training accuracy= 0.981702\n",
      "Epoch: 23 training accuracy= 0.977725\n",
      "Epoch: 24 training accuracy= 0.980111\n",
      "Epoch: 25 training accuracy= 0.982498\n",
      "Epoch: 26 training accuracy= 0.982498\n",
      "Epoch: 27 training accuracy= 0.984885\n",
      "Epoch: 28 training accuracy= 0.982498\n",
      "Epoch: 29 training accuracy= 0.980907\n",
      "Epoch: 30 training accuracy= 0.97852\n",
      "Epoch: 31 training accuracy= 0.983294\n",
      "Epoch: 32 training accuracy= 0.979316\n",
      "Epoch: 33 training accuracy= 0.984089\n",
      "Epoch: 34 training accuracy= 0.983294\n",
      "Epoch: 35 training accuracy= 0.983294\n",
      "Epoch: 36 training accuracy= 0.984089\n",
      "Epoch: 37 training accuracy= 0.987271\n",
      "Epoch: 38 training accuracy= 0.986476\n",
      "Epoch: 39 training accuracy= 0.984885\n",
      "Epoch: 40 training accuracy= 0.983294\n",
      "Epoch: 41 training accuracy= 0.987271\n",
      "Epoch: 42 training accuracy= 0.98568\n",
      "Epoch: 43 training accuracy= 0.986476\n",
      "Epoch: 44 training accuracy= 0.984885\n",
      "Epoch: 45 training accuracy= 0.987271\n",
      "Epoch: 46 training accuracy= 0.989658\n",
      "Epoch: 47 training accuracy= 0.988067\n",
      "Epoch: 48 training accuracy= 0.991249\n",
      "Epoch: 49 training accuracy= 0.989658\n",
      "Epoch: 50 training accuracy= 0.988862\n",
      "Epoch: 51 training accuracy= 0.988862\n",
      "Epoch: 52 training accuracy= 0.989658\n",
      "Epoch: 53 training accuracy= 0.991249\n",
      "Epoch: 54 training accuracy= 0.990453\n",
      "Epoch: 55 training accuracy= 0.991249\n",
      "Epoch: 56 training accuracy= 0.992045\n",
      "Epoch: 57 training accuracy= 0.992045\n",
      "Epoch: 58 training accuracy= 0.988862\n",
      "Epoch: 59 training accuracy= 0.991249\n",
      "Epoch: 60 training accuracy= 0.991249\n",
      "Epoch: 61 training accuracy= 0.991249\n",
      "Epoch: 62 training accuracy= 0.992045\n",
      "Epoch: 63 training accuracy= 0.99284\n",
      "Epoch: 64 training accuracy= 0.992045\n",
      "Epoch: 65 training accuracy= 0.989658\n",
      "Epoch: 66 training accuracy= 0.991249\n",
      "Epoch: 67 training accuracy= 0.992045\n",
      "Epoch: 68 training accuracy= 0.992045\n",
      "Epoch: 69 training accuracy= 0.99284\n",
      "Epoch: 70 training accuracy= 0.99284\n",
      "Epoch: 71 training accuracy= 0.993636\n",
      "Epoch: 72 training accuracy= 0.99284\n",
      "Epoch: 73 training accuracy= 0.993636\n",
      "Epoch: 74 training accuracy= 0.993636\n",
      "Epoch: 75 training accuracy= 0.994431\n",
      "Epoch: 76 training accuracy= 0.99284\n",
      "Epoch: 77 training accuracy= 0.993636\n",
      "Epoch: 78 training accuracy= 0.994431\n",
      "Epoch: 79 training accuracy= 0.995227\n",
      "Epoch: 80 training accuracy= 0.995227\n",
      "Epoch: 81 training accuracy= 0.99284\n",
      "Epoch: 82 training accuracy= 0.994431\n",
      "Epoch: 83 training accuracy= 0.996818\n",
      "Epoch: 84 training accuracy= 0.99284\n",
      "Epoch: 85 training accuracy= 0.995227\n",
      "Epoch: 86 training accuracy= 0.996818\n",
      "Epoch: 87 training accuracy= 0.996022\n",
      "Epoch: 88 training accuracy= 0.996022\n",
      "Epoch: 89 training accuracy= 0.997613\n",
      "Epoch: 90 training accuracy= 0.996022\n",
      "Epoch: 91 training accuracy= 0.996818\n",
      "Epoch: 92 training accuracy= 0.997613\n",
      "Epoch: 93 training accuracy= 0.996022\n",
      "Epoch: 94 training accuracy= 0.996022\n",
      "Epoch: 95 training accuracy= 0.996022\n",
      "Epoch: 96 training accuracy= 0.995227\n",
      "Epoch: 97 training accuracy= 0.994431\n",
      "Epoch: 98 training accuracy= 0.996022\n",
      "Epoch: 99 training accuracy= 0.996022\n",
      "Epoch: 100 training accuracy= 0.996022\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.968518\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess=tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(len(x_train)/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        # Fit training using batch data\n",
    "        x_batch, y_batch = random_batch(x_train, y_train, batch_size)\n",
    "        sess.run(optimizer, feed_dict={x: x_batch,y: y_batch})\n",
    "        acc_train = sess.run(accuracy,feed_dict={x: x_train, y: y_train})\n",
    "        # Display logs per epoch step\n",
    "    print(\"Epoch:\",epoch+1, \"training accuracy=\",acc_train)\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "acc_test=sess.run(accuracy,feed_dict={x: x_test, y: y_test})\n",
    "print (\"Testing Accuracy:\", acc_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test_list=x_test[4:5]\n",
    "# plot_images(test_list)\n",
    "pred=sess.run(y_pred,feed_dict={x: test_list})\n",
    "print(pred)\n",
    "# print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
