{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "[7 3 4 6 1 8 1 0 9 8]\n",
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/\",one_hot=False)\n",
    "x_train = mnist.train.images\n",
    "x_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")\n",
    "\n",
    "print(y_train[:10])\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 500\n",
    "\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"x\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_inputs, n_hidden1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden1, n_hidden1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden1, n_outputs]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_outputs]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    layer_1 = tf.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    layer_2 = tf.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']), biases['b1']))\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']),biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "logits=neural_net(x)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "y_pred=tf.argmax(tf.nn.softmax(logits),1)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.9490782  -0.09050789 -1.028579   ...,  0.16367616  0.20320557\n",
      "  -0.37227884]\n",
      " [ 1.48119473  0.05844649 -0.01930961 ..., -0.77872777  0.89223772\n",
      "  -0.77869785]\n",
      " [-0.23355654 -1.43598664  0.63015658 ..., -0.3187179   0.06657539\n",
      "   1.24643338]\n",
      " ..., \n",
      " [ 0.77279347  1.60306108  0.76055354 ..., -2.53107047  0.90506959\n",
      "  -0.1515445 ]\n",
      " [ 1.01379538  0.56812149 -1.15420663 ..., -1.0554775  -1.12567139\n",
      "   1.22673225]\n",
      " [ 1.01276183 -0.77486658  0.78975958 ...,  0.05539242  2.48688769\n",
      "  -0.64421326]]\n",
      "[[ 1.72961032  0.23522188 -0.42115936 ..., -0.37156811 -0.29385343\n",
      "   1.03912592]\n",
      " [ 0.57877147 -0.13703623  0.60205412 ..., -1.19744563 -1.3690815\n",
      "  -0.5749433 ]\n",
      " [ 0.07238838  0.61237812 -0.11987276 ..., -1.95239174 -1.33797681\n",
      "   1.32151687]\n",
      " ..., \n",
      " [-0.55787563  1.04106724  0.71556073 ..., -1.52708459 -0.77064079\n",
      "   0.78119123]\n",
      " [ 0.03722174  0.24532999  0.03423243 ..., -0.68687952  0.4178305\n",
      "   0.29192299]\n",
      " [ 1.11446106  2.02910709 -2.42288923 ...,  0.02859091  0.9048233\n",
      "  -0.22888698]]\n",
      "0 Train accuracy: 0.64 Test accuracy: 0.6202\n",
      "1 Train accuracy: 0.72 Test accuracy: 0.7124\n",
      "2 Train accuracy: 0.8 Test accuracy: 0.7515\n",
      "3 Train accuracy: 0.78 Test accuracy: 0.7776\n",
      "4 Train accuracy: 0.86 Test accuracy: 0.7928\n",
      "5 Train accuracy: 0.86 Test accuracy: 0.8051\n",
      "6 Train accuracy: 0.86 Test accuracy: 0.8164\n",
      "7 Train accuracy: 0.86 Test accuracy: 0.8225\n",
      "8 Train accuracy: 0.88 Test accuracy: 0.8301\n",
      "9 Train accuracy: 0.86 Test accuracy: 0.8363\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "print(session.run(weights['h1']))\n",
    "print(session.run(weights['out']))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(mnist.train.num_examples // batch_size):\n",
    "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        session.run(training_op, feed_dict={x: X_batch, y: y_batch})\n",
    "    acc_train = session.run(accuracy,feed_dict={x: X_batch, y: y_batch})\n",
    "    acc_test = session.run(accuracy,feed_dict={x: x_test, y: y_test})\n",
    "    print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "    #print(session.run(weights['out']))\n",
    "save_path = saver.save(session, \"models/ann_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.9490782  -0.09050789 -1.028579   ...,  0.16367616  0.20320557\n",
      "  -0.37227884]\n",
      " [ 1.48119473  0.05844649 -0.01930961 ..., -0.77872777  0.89223772\n",
      "  -0.77869785]\n",
      " [-0.23355654 -1.43598664  0.63015658 ..., -0.3187179   0.06657539\n",
      "   1.24643338]\n",
      " ..., \n",
      " [ 0.77279347  1.60306108  0.76055354 ..., -2.53107047  0.90506959\n",
      "  -0.1515445 ]\n",
      " [ 1.01379538  0.56812149 -1.15420663 ..., -1.0554775  -1.12567139\n",
      "   1.22673225]\n",
      " [ 1.01276183 -0.77486658  0.78975958 ...,  0.05539242  2.48688769\n",
      "  -0.64421326]]\n",
      "[[ 1.69077575  0.16812265 -0.41947716 ..., -0.4824678  -0.29664937\n",
      "   1.00962043]\n",
      " [ 0.49844807 -0.13013525  0.80676562 ..., -1.426373   -1.22138536\n",
      "  -0.94535005]\n",
      " [ 0.0289442   0.5662353  -0.07758452 ..., -1.90112197 -1.26389396\n",
      "   1.14746368]\n",
      " ..., \n",
      " [-0.69861138  1.10174155  0.64326829 ..., -1.4441855  -0.72143114\n",
      "   0.81032687]\n",
      " [-0.03765244  0.28603664  0.06127573 ..., -0.7359603   0.45386949\n",
      "   0.28063753]\n",
      " [ 1.1237359   1.89784157 -2.31090283 ..., -0.11346177  0.83574325\n",
      "  -0.31824163]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(weights['h1']))\n",
    "print(session.run(weights['out']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADXNJREFUeJzt3W+oXPWdx/HPR01BkkDM5jYEG/fW\nRpaESJPlJixElmy6LVYLsSKSPChZkaZoha32gZIVNw8UZNmm+GAp3K6xcVNNNa0YJaxxgyjFtXiN\nWW9Sd9c/3NCEmHtDirUR04397oN7Uq5658zNzJk5M/m+X3C5M+d7zpwvJ/ncc2Z+M/NzRAhAPhfV\n3QCAehB+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJXdLNnS1YsCAGBwe7uUsglbGxMZ08edIz\nWbet8Nu+VtJDki6W9K8R8WDZ+oODgxoZGWlnlwBKDA0NzXjdli/7bV8s6V8kfV3SMkkbbS9r9fEA\ndFc7z/lXS3o7It6NiD9I2iVpfTVtAei0dsJ/uaTfTLl/tFj2CbY32x6xPTIxMdHG7gBUqeOv9kfE\ncEQMRcTQwMBAp3cHYIbaCf8xSYun3P9CsQxAH2gn/K9Kusr2F21/TtIGSXuqaQtAp7U81BcRZ23f\nIek5TQ71bY+Iw5V1BqCj2hrnj4i9kvZW1AuALuLtvUBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEH\nkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTh\nB5Ii/EBShB9IivADSRF+ICnCDyTV1iy9tsckfSDpY0lnI2KoiqbwSQcOHCit33jjjQ1rY2NjFXfT\nO/bt21daX7p0acPa4sWLq26n77QV/sLfRMTJCh4HQBdx2Q8k1W74Q9I+26/Z3lxFQwC6o93L/msi\n4pjtz0t63vZ/R8RLU1co/ihslqQrrriizd0BqEpbZ/6IOFb8Hpf0lKTV06wzHBFDETE0MDDQzu4A\nVKjl8NuebXvuuduSvibpUFWNAeisdi77F0p6yva5x3ksIv69kq4AdFzL4Y+IdyV9ucJe0MBzzz1X\nWj9z5kyXOukte/bsKa1v3769YW3Xrl1Vt9N3GOoDkiL8QFKEH0iK8ANJEX4gKcIPJFXFp/rQprNn\nz5bW9+7d26VO+svQUPknyLdt29awdvr06dJtZ8+e3VJP/YQzP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8kxTh/D3jhhRdK6y+//HJp/e67766ynb5x6tSp0vrhw4cb1j788MPSbRnnB3DBIvxAUoQfSIrw\nA0kRfiApwg8kRfiBpBjn74LR0dHS+oYNG0rrS5YsKa1v2bLlvHu6EDT76m6U48wPJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0k1Hee3vV3SNySNR8TyYtl8ST+TNChpTNLNEfHbzrXZ3x544IHSerPPlu/c\nubO0PmfOnPPuqR80+7z+iy++WFq3XWU7F5yZnPl/IunaTy27R9L+iLhK0v7iPoA+0jT8EfGSpE//\nCV4vaUdxe4ekGyruC0CHtfqcf2FEHC9uvydpYUX9AOiStl/wi4iQFI3qtjfbHrE9MjEx0e7uAFSk\n1fCfsL1Ikorf441WjIjhiBiKiKGBgYEWdwegaq2Gf4+kTcXtTZKerqYdAN3SNPy2H5f0n5L+wvZR\n27dKelDSV22/Jelvi/sA+kjTcf6I2Nig9JWKe+lbu3fvLq3v3bu3tN7s8/qrVq06754uBPfff39p\nvdk4/tq1axvW5s2b10pLFxTe4QckRfiBpAg/kBThB5Ii/EBShB9Iiq/ursCTTz5ZWj99+nRp/bbb\nbquynb4xNjZWWn/sscdK65dcUv7f9957721YmzVrVum2GXDmB5Ii/EBShB9IivADSRF+ICnCDyRF\n+IGkGOefoffff79h7ZVXXmnrsW+//fa2tu9Xw8PDpfVmX/u2bNmy0vq6devOu6dMOPMDSRF+ICnC\nDyRF+IGkCD+QFOEHkiL8QFKM88/QmTNnGtaOHj1auu3GjY2+/Ty3d955p63tly9fXlEnOXHmB5Ii\n/EBShB9IivADSRF+ICnCDyRF+IGkmo7z294u6RuSxiNiebFsq6RvSzr3gestEVE+D3Wfmzt3bsPa\nihUrSrcdHR0trZ86daq0Pn/+/NJ6LxsfH29YazbfQTNr1qxpa/vsZnLm/4mka6dZ/sOIWFH8XNDB\nBy5ETcMfES9JKj81Aeg77Tznv8P2G7a3276sso4AdEWr4f+RpC9JWiHpuKQfNFrR9mbbI7ZHmn0n\nG4DuaSn8EXEiIj6OiD9K+rGk1SXrDkfEUEQMDQwMtNongIq1FH7bi6bc/aakQ9W0A6BbZjLU97ik\ntZIW2D4q6R8lrbW9QlJIGpP0nQ72CKADmoY/Iqb7MPrDHeilp1166aUNa0uWLCnddvfu3aX166+/\nvrR+1113ldY76dCh8ou6Zp/JP3LkSMOa7ZZ6Oueii3iPWjs4ekBShB9IivADSRF+ICnCDyRF+IGk\n+OruCmzdurW0HhGl9Weffba0vmHDhvNtqTLN3pXZbLju5MmTVbbzCbfcckvHHjsDzvxAUoQfSIrw\nA0kRfiApwg8kRfiBpAg/kBTj/BVYunRpaf2JJ54orb/++uul9Xansm7HTTfd1Nb2mzZtaljbuXNn\nW49d9jFrNMeZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSYpy/B6xcubKtei+78sorO/bYzaY+v/rq\nqzu27wsBZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrpOL/txZIelbRQUkgajoiHbM+X9DNJg5LG\nJN0cEb/tXKvoR2VzFjSbz6AZxvHbM5Mz/1lJ34+IZZL+StJ3bS+TdI+k/RFxlaT9xX0AfaJp+CPi\neEQcKG5/IOlNSZdLWi9pR7HaDkk3dKpJANU7r+f8tgclrZT0K0kLI+J4UXpPk08LAPSJGYff9hxJ\nP5f0vYj43dRaTD55m/YJnO3Ntkdsj0xMTLTVLIDqzCj8tmdpMvg/jYhfFItP2F5U1BdJGp9u24gY\njoihiBhqNukjgO5pGn5PTsP6sKQ3I2LblNIeSee+mnWTpKerbw9Ap8zkI71rJH1L0qjtg8WyLZIe\nlPSE7VslHZF0c2daRD8rm8K72fTe6Kym4Y+IX0pq9K/0lWrbAdAtvMMPSIrwA0kRfiApwg8kRfiB\npAg/kBRf3Y2O+uijj1relim4O4szP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTg/OuqRRx5pWJs3\nb17ptvfdd1/V7WAKzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/OioVatWNazdeeedpduuW7eu\n6nYwBWd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iq6Ti/7cWSHpW0UFJIGo6Ih2xvlfRtSRPFqlsi\nYm+nGkV/euaZZ+puAQ3M5E0+ZyV9PyIO2J4r6TXbzxe1H0bEP3euPQCd0jT8EXFc0vHi9ge235R0\neacbA9BZ5/Wc3/agpJWSflUsusP2G7a3276swTabbY/YHpmYmJhuFQA1mHH4bc+R9HNJ34uI30n6\nkaQvSVqhySuDH0y3XUQMR8RQRAwNDAxU0DKAKswo/LZnaTL4P42IX0hSRJyIiI8j4o+Sfixpdefa\nBFC1puG3bUkPS3ozIrZNWb5oymrflHSo+vYAdMpMXu1fI+lbkkZtHyyWbZG00fYKTQ7/jUn6Tkc6\nBNARM3m1/5eSPE2JMX2gj/EOPyApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk\nCD+QFOEHkiL8QFKOiO7tzJ6QdGTKogWSTnatgfPTq731al8SvbWqyt7+PCJm9H15XQ3/Z3Zuj0TE\nUG0NlOjV3nq1L4neWlVXb1z2A0kRfiCpusM/XPP+y/Rqb73al0Rvraqlt1qf8wOoT91nfgA1qSX8\ntq+1/T+237Z9Tx09NGJ7zPao7YO2R2ruZbvtcduHpiybb/t5228Vv6edJq2m3rbaPlYcu4O2r6up\nt8W2X7D9a9uHbf99sbzWY1fSVy3HreuX/bYvlvS/kr4q6aikVyVtjIhfd7WRBmyPSRqKiNrHhG3/\ntaTfS3o0IpYXy/5J0qmIeLD4w3lZRNzdI71tlfT7umduLiaUWTR1ZmlJN0j6O9V47Er6ulk1HLc6\nzvyrJb0dEe9GxB8k7ZK0voY+el5EvCTp1KcWr5e0o7i9Q5P/ebquQW89ISKOR8SB4vYHks7NLF3r\nsSvpqxZ1hP9ySb+Zcv+oemvK75C0z/ZrtjfX3cw0FhbTpkvSe5IW1tnMNJrO3NxNn5pZumeOXSsz\nXleNF/w+65qI+EtJX5f03eLytifF5HO2XhqumdHMzd0yzczSf1LnsWt1xuuq1RH+Y5IWT7n/hWJZ\nT4iIY8XvcUlPqfdmHz5xbpLU4vd4zf38SS/N3DzdzNLqgWPXSzNe1xH+VyVdZfuLtj8naYOkPTX0\n8Rm2ZxcvxMj2bElfU+/NPrxH0qbi9iZJT9fYyyf0yszNjWaWVs3HrudmvI6Irv9Iuk6Tr/i/I+kf\n6uihQV9XSvqv4udw3b1JelyTl4H/p8nXRm6V9GeS9kt6S9J/SJrfQ739m6RRSW9oMmiLaurtGk1e\n0r8h6WDxc13dx66kr1qOG+/wA5LiBT8gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0n9P62zHct+\nQVSAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ad392e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "[7 2 1 0 4 1 4 9 6 9 0 8 9 0 1 5 9 7 3 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 6 1 1 7 4 8 2 5 3 2 4 4 6 3 5 5 6 0 4 1 9 7 7 8 2 3 7 4 3 4 3 0 7 0 3 7\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 5 6 1 3 6 9 3 1 4 1 3 6 9]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xt=x_test[4:5]\n",
    "plt.imshow(xt.reshape((28,28)), cmap='binary')\n",
    "plt.show()\n",
    "print(y_test[4:5])\n",
    "\n",
    "#print(xt.shape)\n",
    "\n",
    "xt=x_test[:100]\n",
    "yt=session.run(y_pred,feed_dict={x: xt})\n",
    "print(yt)\n",
    "\n",
    "print(y_test[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
